{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baxter/tensorflow/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the external functions to read the image datasets\n",
    "import build_cgd_train\n",
    "import build_cgd_test\n",
    "train_data, train_targets = build_cgd_train.read_train_data()\n",
    "test_data, test_targets = build_cgd_test.read_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the data lists imported before into numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_targets = np.array(train_targets)\n",
    "test_data = np.array(test_data)\n",
    "test_targets = np.array(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train dataset shape:', (4936, 150528))\n",
      "('Train targets shape:', (4936, 5))\n",
      "('Test set shape:', (177, 150528))\n",
      "('Test targets shape:', (177, 5))\n"
     ]
    }
   ],
   "source": [
    "#Check the input shape for both train and test set\n",
    "print('Train dataset shape:', train_data.shape)\n",
    "print('Train targets shape:', train_targets.shape)\n",
    "print('Test set shape:', test_data.shape)\n",
    "print('Test targets shape:', test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model architecture.\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.engine import topology\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    \n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=5, strides=2, padding='same',\n",
    "                            use_bias=True, kernel_initializer='random_uniform', \n",
    "                            bias_initializer='zeros'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "    \n",
    "    model.add(layers.Conv1D(filters=128, kernel_size=3, strides=2, padding='same',\n",
    "                            use_bias=True, kernel_initializer='random_uniform', \n",
    "                            bias_initializer='zeros'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "    \n",
    "    model.add(layers.Conv1D(filters=128, kernel_size=3, strides=2, padding='same',\n",
    "                            use_bias=True, kernel_initializer='random_uniform', \n",
    "                            bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(layers.Conv1D(filters=128, kernel_size=3, strides=2, padding='same',\n",
    "                            use_bias=True, kernel_initializer='random_uniform', \n",
    "                            bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(layers.Conv1D(filters=256, kernel_size=3, strides=2, padding='same',\n",
    "                            use_bias=True, kernel_initializer='random_uniform', \n",
    "                            bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(5))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, \n",
    "                       epsilon=None, decay=0.0, amsgrad=False)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_7: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9701f580eef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-38ab46a0dd7b>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     model.add(layers.Conv1D(filters=64, kernel_size=5, strides=2, padding='same',\n\u001b[1;32m     16\u001b[0m                             \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                             bias_initializer='zeros'))\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    520\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_7: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "model = build_model()\n",
    "history = model.fit(train_data, train_targets, epochs=30, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_v2()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define custom loss function, metrics, and grasp_to_bboxes\n",
    "import tensorflow as tf\n",
    "from shapely.geometry import Polygon\n",
    "import math\n",
    "from keras import backend as K\n",
    "\n",
    "def grasps_to_bboxes(grasp):\n",
    "    #Order of input: x, y, tan, h, w\n",
    "    bbox = []\n",
    "    x = grasp[0]\n",
    "    y = grasp[1]\n",
    "    tan = grasp[2]\n",
    "    h = grasp[3]\n",
    "    w = grasp[4]\n",
    "    \n",
    "    theta = tf.atan(tan);\n",
    "    \n",
    "    bbox.append(x+((-w/2)*tf.cos(theta))-((-h/2)*tf.sin(theta)))\n",
    "    bbox.append(y+((-h/2)*tf.cos(theta))+((-w/2)*tf.sin(theta)))\n",
    "    bbox.append(x+((-w/2)*tf.cos(theta))-((h/2)*tf.sin(theta)))\n",
    "    bbox.append(y+((h/2)*tf.cos(theta))+((-w/2)*tf.sin(theta)))\n",
    "    bbox.append(x+((w/2)*tf.cos(theta))-((h/2)*tf.sin(theta)))\n",
    "    bbox.append(y+((h/2)*tf.cos(theta))+((w/2)*tf.sin(theta)))\n",
    "    bbox.append(x+((w/2)*tf.cos(theta))-((-h/2)*tf.sin(theta)))\n",
    "    bbox.append(y+((-h/2)*tf.cos(theta))+((w/2)*tf.sin(theta)))\n",
    "    \n",
    "    bbox = np.array(bbox)\n",
    "    return bbox\n",
    "    \n",
    "    \n",
    "def rsse_loss_function(y_true, y_pred):\n",
    "    #Order of output: x, y, tan, h, w\n",
    "    tan_hat = y_pred[2]\n",
    "    tan_hat_confined = tf.minimum(11., tf.maximum(-11., tan_hat))\n",
    "    tan = y_true[2]\n",
    "    tan_confined = tf.minimum(11., tf.maximum(-11., tan))\n",
    "    gamma = tf.constant(10.)\n",
    "    loss = tf.pow(y_pred[0] - y_true[0], 2) + tf.pow(y_pred[1] - y_true[1], 2) + gamma*tf.pow(tan_hat_confined - tan_confined, 2) + tf.pow(y_pred[3] - y_true[3], 2) + tf.pow(y_pred[4] - y_true[4], 2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def _floats_feature(v):\n",
    "    if not isinstance(v, list):\n",
    "        v = [v]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=v))\n",
    "\n",
    "def rectangle_metric(y_true, y_pred):\n",
    "    rec_true = grasps_to_bboxes(y_true)\n",
    "    rec_pred = grasps_to_bboxes(y_pred)\n",
    "    \n",
    "    \"\"\"poly_true = Polygon([(float(rec_true[0]), float(rec_true[1])), \n",
    "                         (float(rec_true[2]), float(rec_true[3])),\n",
    "                         (float(rec_true[4]), float(rec_true[5])),\n",
    "                         (float(rec_true[6]), float(rec_true[7]))\n",
    "                        ])\n",
    "    poly_pred = Polygon([(float(rec_pred[0]), float(rec_pred[1])),\n",
    "                         (float(rec_pred[2]), float(rec_pred[3])),\n",
    "                         (float(rec_pred[4]), float(rec_pred[5])),\n",
    "                         (float(rec_pred[6]), float(rec_pred[7]))\n",
    "                        ])\"\"\"\n",
    "    \n",
    "    poly_true = Polygon([(rec_true[0:2]), \n",
    "                        (rec_true[2:4]),\n",
    "                        (rec_true[4:6]),\n",
    "                        (rec_true[6:8])])\n",
    "    poly_pred = Polygon([(rec_pred[0:2]), \n",
    "                        (rec_pred[2:4]),\n",
    "                        (rec_pred[4:6]),\n",
    "                        (rec_pred[6:8])])\n",
    "    \n",
    "    iou = poly_true.intersection(poly_pred).area / (poly_true.area +poly_pred.area - poly_true.intersection(poly_pred).area) \n",
    "    angle_diff = K.abs(K.atan(y_pred[2])*180/K.pi -K.atan(y_true[2])*180/K.pi)\n",
    "    \n",
    "    return iou, angle_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iou, angle_diff = rectangle_metric(train_targets[0], train_targets[10])\n",
    "#loss = rsse_loss_function(train_targets[0], train_targets[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define custom loss and metric functions\n",
    "import tensorflow as tf\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def rsse_loss_function(y_true, y_pred):\n",
    "    #Order of output: x, y, tan, h, w\n",
    "    tan_hat = y_pred[2]\n",
    "    tan_hat_confined = tf.minimum(11., tf.maximum(-11., tan_hat))\n",
    "    tan = y_true[2]\n",
    "    tan_confined = tf.minimum(11., tf.maximum(-11., tan))\n",
    "    gamma = 10\n",
    "    loss = tf.reduce_sum(K.pow(y_pred[0] - y_true[0], 2) + tf.pow(y_pred[1] - y_true[1], 2) + gamma*tf.pow(tan_hat_confined - tan_confined, 2) + tf.pow(y_pred[3] - y_true[3], 2) + tf.pow(y_pred[4] - y_true[4], 2))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def rectangle_metric(y_true, y_pred):\n",
    "    poly_true = Polygon(float(grasp_to_rectangle(y_true)))\n",
    "    poly_pred = Polygon(float(grasp_to_rectangle(y_pred)))\n",
    "    \n",
    "    iou = pply_true.intersection(poly_pred).area / (poly_true.area +poly_pred.area - poly_true.intersection(poly_pred).area) \n",
    "    angle_diff = np.abs(np.arctan(y_pred[2])*180/np.pi -np.arctan(y_true[2])*180/np.pi)\n",
    "    \n",
    "    return iou, angle_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-define the model architecture after revised loss and metric functions.\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model_v2():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(5))\n",
    "    model.compile(optimizer='rmsprop', loss=rsse_loss_function, metrics=[rectangle_metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('processing fold #', 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ab8577dc6645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Build the Keras model (already compiled)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Train the model (in silent mode, verbose=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     model.fit(partial_train_data, partial_train_targets,\n",
      "\u001b[0;32m<ipython-input-48-c123510ba497>\u001b[0m in \u001b[0;36mbuild_model_v2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsse_loss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrectangle_metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    912\u001b[0m                             metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    913\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                                                                mask=masks[i])\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                         \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/baxter/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-8e12df732b27>\u001b[0m in \u001b[0;36mrectangle_metric\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrectangle_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpoly_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasp_to_rectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mpoly_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasp_to_rectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples,]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples,]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model_v2()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    # Evaluate the model on the validation data\n",
    "    val_loss, val_iou, val_angle_diff = model.evaluate(val_data, val_targets, verbose=1)\n",
    "    all_scores.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
